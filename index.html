<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Marshall Ward">
  <meta name="dcterms.date" content="2022-03-01">
  <title>Estimating and measuring peak performance of numerical ocean model algorithms</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./reveal.js/dist/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="./reveal.js/css/theme/gfdl.css" id="theme">
  <!-- Explicitly add zenburn for highlight support -->
  <link rel="stylesheet" href="./reveal.js/plugin/highlight/zenburn.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? './reveal.js/css/print/pdf.scss' : './reveal.js/css/print/paper.scss';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="./reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <base href="./index.html">
</head>
<body>
  <div class="reveal"
       style="background: url(img/bg_gfdl.jpg);
              background-size: cover;">

    <!-- Original ratio: 10.04" x 7.08" -->
    <!-- the globe is distracting...
    <div style="height: 100vh; position: absolute; bottom: -50vh; left: -40vh">
      <img style="height: 100vh; width: 142vh" src="img/bg_globe.png">
    </div>
    -->

    <header style="width: 10vh; position: absolute; bottom: 2vh; right: 2vh;">
      <img src="img/noaa_logo.png">
    </header>

    <footer style="font-size: 1pc; position: absolute; bottom: 2%; left: 2%;">
      <code><p><a href="https://marshallward.org/os2022.html">https://marshallward.org/os2022.html</a></p></code>
    </footer>

    <div class="slides">

<section id="title-slide">
  <!--div class="reveal" style="text-align: right;">
    <img src="img/noaa_logo.png"
         style="background: none; border: none; box-shadow: none;
         width: 30%"
         alt="NCI">
  </div-->
  <h2 class="title">Estimating and measuring peak performance of numerical ocean model algorithms</h2>
  <p class="author" style="text-align: right;">Marshall Ward</p>
  <p class="organization" style="text-align: right;">NOAA-GFDL</p>
  <p class="date" style="text-align: right;">March 1, 2022</p>
  <!-- Currently cannot add notes to a title slide, so have to do manually-->
  <aside class="notes">
    <p>"Performance" is overall a generic term which different meanings.</p>
    <p>Numerical analysts often focus on accuracy and convergence rates of errors, with less discussion of the raw computational cost.</p>
    <ul>
    <li>If the cost of each iteration is enormous, then convergence rate is a poor predictor of runtime.</li>
    </ul>
    <p>Model usage is often measured in throughput, such as "SYPD" or simulated years per day.</p>
    <ul>
    <li>This is a perfect metric, but perhaps too reductive. Comparison across models becomes impossible, and leaves very little sense of how well we could have done, or ought to do.</li>
    </ul>
    <p>Computational performance tries to decompose the problem into measurable units of calculation, with FLOPs being the most well known.</p>
    <ul>
    <li>It is also flawed (some reasons we'll address) but is nonetheless a useful "unit of work" for calculation, and maps well onto the computer's own unit of time (clock frequency), so it has the <em>potential</em> to make predictive statements of run time.</li>
    </ul>
    <p>No single method can alone characterize performance.</p>
    <p>We generally do a good job quantifying the first two, but reporting the absolute performance of a model is uncommon.</p>
    <p>I am hoping that this talk will help to start providing some basis for this third point, and to help us start making confident estimates of how we're doing, and how we ought to do. Introductory comments, written to slide notes</p>
  </aside>
</section>

<section>
<section id="peak-performance" class="title-slide slide level1">
<h1>Peak Performance</h1>
<p><span class="math display">\[W_\text{FLOPS} = W_\text{core} \times N_\text{cores} \times f_\text{cycles}\]</span></p>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>Year</th>
<th>Theoretical</th>
<th>Observed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cascade Lake</td>
<td>2019</td>
<td>2150.4</td>
<td>2145.3</td>
</tr>
<tr class="even">
<td>Volta (GPU)</td>
<td>2018</td>
<td>7065.6</td>
<td>7007.3</td>
</tr>
</tbody>
</table>
<p>But are these numbers achievable?</p>
</section>
<section id="how-we-compute" class="slide level2">
<h2>How we compute</h2>
<dl>
<dt>Cascade Lake</dt>
<dd><p>24 core × 8 (AVX512) × 2 (FMA) × 2 port × 2.8 GHz</p>
</dd>
<dt>Volta</dt>
<dd><p>80 SM × 32 FP64 core × 2 (FMA) × 1.38 GHz</p>
</dd>
</dl>
</section>
<section id="cost-of-business" class="slide level2">
<h2>Cost of Business</h2>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>FLOPs</th>
<th>Year</th>
<th>Price</th>
<th>TDP(W)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cascade Lake</td>
<td>2145.3</td>
<td>2019</td>
<td>$6432</td>
<td>240</td>
</tr>
<tr class="even">
<td>Volta (GPU)</td>
<td>7007.3</td>
<td>2018</td>
<td>$8999</td>
<td>250</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Cascade Lake: Q2'19 Volta V100: Q1'18</p>
</aside>
</section>
<section id="models" class="slide level2">
<h2>Models</h2>
<dl>
<dt>Cascade Lake</dt>
<dd><p>Intel(R) Xeon(R) Platinum 8274 CPU @ 3.20GHz</p>
</dd>
<dt>Volta</dt>
<dd><p>Nvidia Volta GV100 (1.38GHz)</p>
</dd>
</dl>
</section></section>
<section id="performance-bounds" class="title-slide slide level1">
<h1>Performance Bounds</h1>
<p><img data-src="img/dgemm.svg" alt="image" /></p>
<aside class="notes">
<ul>
<li>x: length of array, or sqrt(dim) of square matrix</li>
<li>Nvidia DGEMM and DAXPY from cuBLAS</li>
<li>Intel DGEMM results from MKL</li>
<li>Intel DAXPY results from Optiflop</li>
</ul>
<p>Note: Optiflop DAXPY results agree with cuBLAS.</p>
</aside>
</section>

<section id="performance-bounds-1" class="title-slide slide level1">
<h1>Performance Bounds</h1>
<p><img data-src="img/dgemm_vs_daxpy.svg" alt="image" /></p>
<aside class="notes">
<ul>
<li>x: length of array, or sqrt(dim) of square matrix</li>
<li>Nvidia DGEMM and DAXPY from cuBLAS</li>
<li>Intel DGEMM results from MKL</li>
<li>Intel DAXPY results from Optiflop</li>
</ul>
<p>Note: Optiflop DAXPY results agree with cuBLAS.</p>
</aside>
</section>

<section>
<section id="compute-bound" class="title-slide slide level1">
<h1>Compute Bound</h1>
<p>Matrix Multiplication (<code>DGEMM</code>)</p>
<p><span class="math display">\[\text{C}_{ij} = \sum_{k} A_{ik} B_{kj}\]</span><span class="math display">\[\frac{\text{FLOPs}}{\text{byte}}
   = \frac{2n^3}{3n^2 \times \texttt{sizeof}(A)}
   = \frac{1}{12} n\]</span></p>
<p>Efficiency (work/byte) increases as problem grows</p>
</section>
<section id="traditional-cfd" class="slide level2">
<h2>Traditional CFD</h2>
<p>Most solvers are hyperbolic and elliptic, e.g.:</p>
<p><span class="math display">\[\frac{\partial \mathbf{u}}{\partial t} =
      - \mathbf{u} \cdot \nabla \mathbf{u} -\nabla p + \mathcal{F}\]</span><span class="math display">\[\nabla^2 p = -\nabla \left( \mathbf{u} \cdot \nabla \mathbf{u} \right)
      - \nabla \cdot \mathcal{F}\]</span></p>
<p>Pressure (Montgomery potential, PV, ...) solver is a (sparse) matrix operation.</p>
</section></section>
<section>
<section id="memory-bound" class="title-slide slide level1">
<h1>Memory Bound</h1>
<p>Field update (<code>DAXPY</code>)</p>
<p><span class="math display">\[\phi_{i} = \phi_{i} + \Delta t \mathcal{F}_{i}\]</span><span class="math display">\[\frac{\text{FLOPs}}{\text{byte}}
   = \frac{2n}{3n \times \texttt{sizeof} (\phi)}
   = \frac{1}{12}\]</span></p>
<p>Bandwidth cost rises in proportion to work</p>
</section>
<section id="ocean-cfd" class="slide level2">
<h2>Ocean CFD</h2>
<p>Hydrostatic balance eliminates elliptic step:</p>
<p><span class="math display">\[\frac{\partial \mathbf{u}}{\partial t} =
      - \mathbf{u} \cdot \nabla \mathbf{u} -\nabla p + \mathcal{F}\]</span><span class="math display">\[p = -g \rho\]</span><span class="math display">\[\frac{\partial \rho}{\partial t} = ...\]</span></p>
<p>Most barotropic solvers are also hyperbolic.</p>
</section></section>
<section>
<section id="array-performance" class="title-slide slide level1">
<h1>Array Performance</h1>
<p><img data-src="img/cascade_lake_flops.svg" alt="image" /></p>
<aside class="notes">
<p>Difference expressions will exhibit</p>
</aside>
</section>
<section id="how-these-are-produced" class="slide level2">
<h2>How these are produced</h2>
<pre class="c"><code>int main() {
   /* ... */
   start(timer);
   for (r = 0; r &lt; r_max; r++) {
       for (int i = 0; i &lt; n; i++)
           kernel(i, a, b, x, y);

       // An impossible branch to block loop interchange
       if (y[0] &lt; 0.) dummy(a, b, x, y);
   }
   stop(timer);
}

void kernel(int i, double a, double b, double *x, double *y) {
    y[i] = a * x[i] + y[i];
}</code></pre>
<p>Apply artificially high iteration, but let the compiler construct the kernel.</p>
</section>
<section id="unaccounted-factors" class="slide level2">
<h2>Unaccounted Factors</h2>
<ul>
<li>Pipelining</li>
<li>Instruction latency</li>
<li>Instruction decoder</li>
<li>Variable Clock Frequency</li>
<li>Depletion of registers</li>
</ul>
</section></section>
<section>
<section id="roofline-modeling" class="title-slide slide level1">
<h1>Roofline Modeling</h1>
<p><img data-src="img/cascade_lake_roofline.svg" style="width:50.0%" alt="image" /></p>
<p><span class="math inline">\(P = I \times B_\text{mem}\)</span></p>
<aside class="notes">
<p>Adjacent lines have the same AI</p>
</aside>
</section>
<section id="the-roofline-model" class="slide level2">
<h2>The Roofline Model</h2>
<p><span class="math display">\[P = \text{min}(P_\text{max}, I \times B_\text{mem})\]</span></p>
<ul>
<li><span class="math inline">\(P\)</span>: Performance (FLOP/s)</li>
<li><span class="math inline">\(P_\text{max}\)</span>: Theoretical peak (FLOP/s)</li>
<li><span class="math inline">\(I\)</span>: Arithmetic Intensity (FLOP/byte)</li>
<li><span class="math inline">\(B_\text{mem}\)</span>: Memory bandwidth (byte/s) (cache, RAM, ...)</li>
</ul>
<p>For our codes, often <span class="math inline">\(P = I \times B_\text{mem}\)</span></p>
<aside class="notes">
<p>Roofline is a useful model for estimating how well we ought to do</p>
<p>However, it can be hard to apply in practice due to a few issues</p>
<ul>
<li>The "peak" and "memory bandwidth" are deliberately ambiguous and can be hard to assign. (RAM? L3&lt;-&gt;L2? etc?)</li>
<li>No real effort to manage competing timescales in the CPU</li>
</ul>
<p>ECM is an alternative model</p>
<p>We want to keep things very simple and just emphasize the role of bandwidth.</p>
</aside>
</section></section>
<section>
<section id="peak-bandwidth" class="title-slide slide level1">
<h1>Peak Bandwidth</h1>
<p><img data-src="img/skylake_mem_block_diagram.svg" class="float float" style="width:45.0%" alt="image" /></p>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>BW (GB/s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 (cache)</td>
<td>8600</td>
</tr>
<tr class="even">
<td>x86 (RAM)</td>
<td>141</td>
</tr>
<tr class="odd">
<td>Volta (RAM)</td>
<td>900</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>"x86" is the Cascade Lake used in the previous figures</p>
<p>"cache" refers to the L1 &lt;-&gt; register transfer speed</p>
</aside>
</section>
<section id="computing-bandwidth" class="slide level2">
<h2>Computing Bandwidth</h2>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>Speed (GHz)</th>
<th>Width (B)</th>
<th>BW (GB/s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 cache</td>
<td>2.8*</td>
<td>128*</td>
<td>8600</td>
</tr>
<tr class="even">
<td>x86 RAM</td>
<td>2.93</td>
<td>8 × 6</td>
<td>141</td>
</tr>
<tr class="odd">
<td>Volta RAM</td>
<td>877</td>
<td>1024</td>
<td>900</td>
</tr>
</tbody>
</table>
<ul>
<li>AVX512 clock speed, L1 load+store, etc</li>
</ul>
<aside class="notes">
<p>"x86" is the Cascade Lake used in the previous figures</p>
<p>"cache" refers to the L1 &lt;-&gt; register transfer speed</p>
</aside>
</section>
<section id="x86-cache-bandwidth" class="slide level2">
<h2>x86 Cache Bandwidth</h2>
<p><img data-src="img/skylake_mem_block_diagram.svg" style="width:65.0%" alt="image" /></p>
<p>Three 64B + AGU ports, but only 2 AGU are usable</p>
<aside class="notes">
<p><a href="https://blogs.fau.de/hager/archives/8683">https://blogs.fau.de/hager/archives/8683</a></p>
</aside>
</section></section>
<section id="euler-step" class="title-slide slide level1">
<h1>Euler Step</h1>
<p><span class="math display">\[\phi^{n+1}_i = \phi^n_i
   + \Delta t \left( \frac{\partial \phi}{\partial t} \right)_i\]</span></p>
<pre class="c"><code>y[i] = y[i] + a * x[i]</code></pre>
<p>2 FLOPs per 3×8 bytes: <span class="math inline">\(\frac{1}{12}\)</span></p>
</section>

<section id="peak-euler" class="title-slide slide level1">
<h1>Peak Euler</h1>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>Observed</th>
<th>Theory</th>
<th>%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 (Cache)</td>
<td>715.1</td>
<td>716.8</td>
<td>99.7</td>
</tr>
<tr class="even">
<td>x86 (RAM)</td>
<td>9.36</td>
<td>11.8</td>
<td>79.3</td>
</tr>
<tr class="odd">
<td>GPU</td>
<td>67.3</td>
<td>74.8</td>
<td>89.9</td>
</tr>
</tbody>
</table>
<aside class="notes">
<dl>
<dt>x86 reg: (128 B/c * 2.8 GHz) * 24 cores * (1/8 FLOP/B)?</dt>
<dd><p>(128 B/c * 2.8 GHz) * 24 cores * (1/12 FLOP/B)?</p>
</dd>
<dt>x86 mem: (2.933GHz * 8 B/c) * (6 channels) * (1/12 FLOP/byte)</dt>
<dd><p>= 11.732</p>
</dd>
<dt>(NOTE: Bandwidth suggests 1/8 due to 128B/s buses, but the "AGU-limit"</dt>
<dd><p>means only 2 of 3 (2L+S) can be used at a time)</p>
<p><a href="https://blogs.fau.de/hager/archives/8683">https://blogs.fau.de/hager/archives/8683</a></p>
</dd>
</dl>
<p>I can't get this 70.9 number anymore..? Now getting 67.3 or so.</p>
</aside>
</section>

<section>
<section id="finite-difference" class="title-slide slide level1">
<h1>Finite Difference</h1>
<p><span class="math display">\[\phi^{n+1}_i = \phi^n_i + \frac{\Delta t}{\Delta x^2}
   \left(\phi^n_{i+1} - 2 \phi^n_i + \phi^n_{i-1} \right)\]</span></p>
<pre class="c"><code>y[i] = a * x[i] + b * (x[i+1] +  x[i-1])

x[i] = y[i]</code></pre>
<p>4 FLOPs (amortized) per 4×8 bytes: <span class="math inline">\(\frac{1}{8}\)</span></p>
</section>
<section id="how-many-flops" class="slide level2">
<h2>How many FLOPS?</h2>
<p>Is it four or five operations?</p>
<p><span class="math display">\[\phi^{n+1}_i = \phi^n_i + \frac{\Delta t}{\Delta x^2}
   \left(\phi^n_{i+1} - 2 \phi^n_i + \phi^n_{i-1} \right)\]</span></p>
<pre class=""><code>y[i] = x[i] + a * (x[i-1] - 2 * x[i] + x[i+1])</code></pre>
<p><span class="math display">\[\phi^{n+1}_i = \left( 1 - 2 \frac{\Delta t}{\Delta x^2} \right) \phi^n_i 
   + \frac{\Delta t}{\Delta x^2} \left(\phi^n_{i+1} + \phi^n_{i-1} \right)\]</span></p>
<pre class=""><code>y[i] = a * x[i] + b * (x[i-1] + x[i+1])</code></pre>
<p>This is a compiler question: Do we follow parentheses?</p>
</section></section>
<section id="diffusion-performance" class="title-slide slide level1">
<h1>Diffusion Performance</h1>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>+1</th>
<th>+8</th>
<th>Theory</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 (Cache)</td>
<td>499.9</td>
<td>646.9</td>
<td>1075.2</td>
</tr>
<tr class="even">
<td>x86 (RAM)</td>
<td>10.5</td>
<td>10.5</td>
<td>17.6</td>
</tr>
<tr class="odd">
<td>GPU</td>
<td>81.1</td>
<td>81.1</td>
<td>112.3</td>
</tr>
</tbody>
</table>
<p>Prediction is significantly higher for <span class="math inline">\(I = \frac{1}{8}\)</span> ?</p>
</section>

<section id="write-allocated-diffusion" class="title-slide slide level1">
<h1>Write-Allocated Diffusion</h1>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>+1</th>
<th>+8</th>
<th>Theory</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 (Cache)</td>
<td>499.9</td>
<td>646.9</td>
<td>716.8</td>
</tr>
<tr class="even">
<td>x86 (RAM)</td>
<td>10.5</td>
<td>10.5</td>
<td>11.7</td>
</tr>
<tr class="odd">
<td>GPU</td>
<td>81.1</td>
<td>81.1</td>
<td>112.3</td>
</tr>
</tbody>
</table>
<p><strong>Write-allocate</strong>: An x86 write (<code>y[:] =</code>) includes a read!</p>
<p>Arithmetic intensity is adjusted to <span class="math inline">\(\frac{1}{12}\)</span> (6 moves)</p>
<aside class="notes">
<p><a href="https://blogs.fau.de/hager/archives/8263">https://blogs.fau.de/hager/archives/8263</a></p>
<p><a href="https://www.cs.virginia.edu/stream/ref.html#counting">https://www.cs.virginia.edu/stream/ref.html#counting</a></p>
<p>Also, Volta seems to have no such issue</p>
</aside>
</section>

<section id="diffusion-stages" class="title-slide slide level1">
<h1>Diffusion Stages</h1>
<table>
<thead>
<tr class="header">
<th>Stage</th>
<th>Observed</th>
<th>Theory</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(y \leftarrow a x + b (x^{-} + x^{+})\)</span></td>
<td>1057 GF/s</td>
<td>1075 GF/s</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x \leftarrow y\)</span></td>
<td>6878 GB/s</td>
<td>8601 GB/s</td>
</tr>
</tbody>
</table>
<p>Copies in general tend to be suboptimal</p>
<p>(Although better than write-allocate)</p>
<aside class="notes">
<p>One issue is that optimal copy is different from optimal compute. I do not know why.</p>
<p>Copy is also more sensitive to peel loops than compute. (Again, dunno why)</p>
</aside>
</section>

<section id="evaluating-model-performance" class="title-slide slide level1">
<h1>Evaluating Model Performance</h1>
<p><img data-src="img/benchmark_topo.svg" class="float float" style="width:35.0%" alt="image" /></p>
<ul>
<li>192 × 128 grid, 75 level
<ul>
<li>32 x 32 per MPI rank</li>
<li>~1.8M points / field</li>
</ul></li>
<li>288 steps (3 day, <span class="math inline">\(\Delta t = 900s\)</span>)</li>
<li>"Benchmark" configuration:
<ul>
<li>Split barotropic</li>
<li>Thermodynamic EOS</li>
<li>Parameterization suite</li>
</ul></li>
</ul>
<aside class="notes">
<ul>
<li><p>So how is MOM6 vectorization?</p>
<ul>
<li>This is a compile-time feature, so ought not depend on scaling</li>
</ul></li>
<li><p>Using a "benchmark" single-core test</p>
<ul>
<li>Reasonable set of realistic components</li>
<li>A non-trivial land/sea distribution</li>
</ul></li>
<li><p>Not necessarily the most physically signficant factors. Just the ones which had a significant impact on performance.</p></li>
</ul>
</aside>
</section>

<section id="mom6-performance" class="title-slide slide level1">
<h1>MOM6 Performance</h1>
<p><img data-src="img/mom6_subrt_flops.svg" alt="image" /></p>
</section>

<section>
<section id="mom6-roofline" class="title-slide slide level1">
<h1>MOM6 Roofline</h1>
<p><img data-src="img/mom6_roofline.svg" style="width:80.0%" alt="image" /></p>
</section>
<section id="mom6-all-subroutines" class="slide level2">
<h2>MOM6: All subroutines</h2>
<p><img data-src="img/mom6_roofline_all_1x.svg" style="width:80.0%" alt="image" /></p>
<p>Largely memory-bound, with notable exceptions</p>
</section>
<section id="mom6-16x-domain" class="slide level2">
<h2>MOM6: 16x Domain</h2>
<p><img data-src="img/mom6_roofline_all_4x.svg" style="width:80.0%" alt="image" /></p>
<p>Memory-bound shift as domain size increases</p>
</section></section>
<section id="summary" class="title-slide slide level1">
<h1>Summary</h1>
<ul>
<li>Most ocean model solvers are bandwidth-limited</li>
<li>Arithmetic intensity (AI) is a predictor of performance</li>
<li>CPUs benefit from modest arrays, but can tolerate larger ones</li>
<li>GPUs <em>strongly favor</em> large arrays, and implicit (matrix) solvers</li>
<li>AI can be used to strategize optimization</li>
</ul>
</section>
    </div>
  </div>

  <script src="./reveal.js/dist/reveal.js"></script>
  <script src="./reveal.js/plugin/math/math.js"></script>
  <script src="./reveal.js/plugin/notes/notes.js"></script>
  <script src="./reveal.js/plugin/highlight/highlight.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          //TeX: {
          //  inlineMath: [['\\(','\\)']],
          //  displayMath: [['\\[','\\]']],
          //  balanceBraces: true,
          //  processEscapes: false,
          //  processRefs: true,
          //  processEnvironments: true,
          //  preview: 'TeX',
          //  skipTags: ['script','noscript','style','textarea','pre','code'],
          //  ignoreClass: 'tex2jax_ignore',
          //  processClass: 'tex2jax_process'
          //},
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: './reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: './reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: './reveal.js/plugin/notes/notes.js', async: true }
        ],
        plugins : [ RevealMath, RevealNotes, RevealHighlight],
      });
    </script>
    </body>
</html>
