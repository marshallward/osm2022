<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Marshall Ward">
  <meta name="dcterms.date" content="2022-03-01">
  <title>Estimating and measuring peak performance of numerical ocean model algorithms</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./reveal.js/dist/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="./reveal.js/css/theme/gfdl.css" id="theme">
  <!-- Explicitly add zenburn for highlight support -->
  <link rel="stylesheet" href="./reveal.js/plugin/highlight/zenburn.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? './reveal.js/css/print/pdf.scss' : './reveal.js/css/print/paper.scss';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="./reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <base href="./index.html">
</head>
<body>
  <div class="reveal"
       style="background: url(img/bg_gfdl.jpg);
              background-size: cover;">

    <!-- Original ratio: 10.04" x 7.08" -->
    <!-- the globe is distracting...
    <div style="height: 100vh; position: absolute; bottom: -50vh; left: -40vh">
      <img style="height: 100vh; width: 142vh" src="img/bg_globe.png">
    </div>
    -->

    <header style="width: 10vh; position: absolute; bottom: 2vh; right: 2vh;">
      <img src="img/noaa_logo.png">
    </header>

    <footer style="font-size: 1pc; position: absolute; bottom: 2%; left: 2%;">
      <code><p><a href="https://marshallward.org/os2022.html">https://marshallward.org/os2022.html</a></p></code>
    </footer>

    <div class="slides">

<section id="title-slide">
  <!--div class="reveal" style="text-align: right;">
    <img src="img/noaa_logo.png"
         style="background: none; border: none; box-shadow: none;
         width: 30%"
         alt="NCI">
  </div-->
  <h1 class="title">Estimating and measuring peak performance of numerical ocean model algorithms</h1>
  <p class="author" style="text-align: right;">Marshall Ward</p>
  <p class="organization" style="text-align: right;"><p>NOAA-GFDL</p></p>
  <p class="date" style="text-align: right;">March 1, 2022</p>
  <!-- Currently cannot add notes to a title slide, so have to do manually-->
  <aside class="notes">
    <p>Introductory comments, written to slide notes</p>
  </aside>
</section>

<section id="describing-performance" class="title-slide slide level1">
<h1>Describing Performance</h1>
<dl>
<dt>Mathematical performance</dt>
<dd><p>Numerical convergence of algorithm?</p>
</dd>
<dt>Operational performance</dt>
<dd><p>Simulation time per runtime</p>
</dd>
<dt>Computational performance</dt>
<dd><p>Operations per second (watt, etc)</p>
</dd>
</dl>
<aside class="notes">
<p>"Performance" is overall a generic term which different meanings.</p>
<p>Numerical analysts often focus on accuracy and convergence rates of errors, with less discussion of the raw computational cost.</p>
<ul>
<li>If the cost of each iteration is enormous, then convergence rate is a poor predictor of runtime.</li>
</ul>
<p>Model usage is often measured in throughput, such as "SYPD" or simulated years per day.</p>
<ul>
<li>This is a perfect metric, but perhaps too reductive. Comparison across models becomes impossible, and leaves very little sense of how well we could have done, or ought to do.</li>
</ul>
<p>Computational performance tries to decompose the problem into measurable units of calculation, with FLOPs being the most well known.</p>
<ul>
<li>It is also flawed (some reasons we'll address) but is nonetheless a useful "unit of work" for calculation, and maps well onto the computer's own unit of time (clock frequency), so it has the <em>potential</em> to make predictive statements of run time.</li>
</ul>
<p>No single method can alone characterize performance.</p>
<p>We generally do a good job quantifying the first two, but reporting the absolute performance of a model is uncommon.</p>
<p>I am hoping that this talk will help to start providing some basis for this third point, and to help us start making confident estimates of how we're doing, and how we ought to do.</p>
</aside>
</section>

<section>
<section id="peak-performance" class="title-slide slide level1">
<h1>Peak Performance</h1>
<p><span class="math display">\[W_\text{FLOPS} = W_\text{core} \times N_\text{cores} \times f_\text{cycles}\]</span></p>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>Year</th>
<th>Theoretical</th>
<th>Observed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Broadwell</td>
<td>2016</td>
<td>1555.2</td>
<td>1553.0</td>
</tr>
<tr class="even">
<td>Cascade Lake</td>
<td>2019</td>
<td>2150.4</td>
<td>2145.3</td>
</tr>
<tr class="odd">
<td>Volta (GPU)</td>
<td>2018</td>
<td>7065.6</td>
<td>7007.3</td>
</tr>
</tbody>
</table>
<p>But are these numbers achievable?</p>
</section>
<section id="how-we-compute" class="slide level2">
<h2>How we compute</h2>
<dl>
<dt>Broadwell</dt>
<dd><p>36 core × 4 (AVX) × 2 (FMA) × 2 port × 2.7 GHz</p>
</dd>
<dt>Cascade Lake</dt>
<dd><p>24 core × 8 (AVX512) × 2 (FMA) × 2 port × 2.8 GHz</p>
</dd>
<dt>Volta</dt>
<dd><p>80 SM × 32 FP64 core × 2 (FMA) × 1.38 GHz</p>
</dd>
</dl>
</section>
<section id="cost-of-business" class="slide level2">
<h2>Cost of Business</h2>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>FLOPs</th>
<th>Year</th>
<th>Price</th>
<th>TDP(W)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Broadwell</td>
<td>1553.0</td>
<td>2016</td>
<td>$2702</td>
<td>145</td>
</tr>
<tr class="even">
<td>Cascade Lake</td>
<td>2145.3</td>
<td>2019</td>
<td>$6432</td>
<td>240</td>
</tr>
<tr class="odd">
<td>Volta (GPU)</td>
<td>7007.3</td>
<td>2018</td>
<td>$8999</td>
<td>250</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Broadwell: Q1'16 Cascade Lake: Q2'19 Volta V100: Q1'18</p>
</aside>
</section>
<section id="models" class="slide level2">
<h2>Models</h2>
<dl>
<dt>Broadwell</dt>
<dd><p>Intel(R) Xeon(R) CPU E5-2697 v4 @ 2.30GHz</p>
</dd>
<dt>Cascade Lake</dt>
<dd><p>Intel(R) Xeon(R) Platinum 8274 CPU @ 3.20GHz</p>
</dd>
<dt>Volta</dt>
<dd><p>Nvidia Volta GV100 (1.38GHz)</p>
</dd>
</dl>
</section></section>
<section id="performance-bounds" class="title-slide slide level1">
<h1>Performance Bounds</h1>
<p><img data-src="img/dgemm.svg" alt="image" /></p>
<aside class="notes">
<ul>
<li>x: length of array, or sqrt(dim) of square matrix</li>
<li>Nvidia DGEMM and DAXPY from cuBLAS</li>
<li>Intel DGEMM results from MKL</li>
<li>Intel DAXPY results from Optiflop</li>
</ul>
<p>Note: Optiflop DAXPY results agree with cuBLAS.</p>
</aside>
</section>

<section id="performance-bounds-1" class="title-slide slide level1">
<h1>Performance Bounds</h1>
<p><img data-src="img/dgemm_vs_daxpy.svg" alt="image" /></p>
<aside class="notes">
<ul>
<li>x: length of array, or sqrt(dim) of square matrix</li>
<li>Nvidia DGEMM and DAXPY from cuBLAS</li>
<li>Intel DGEMM results from MKL</li>
<li>Intel DAXPY results from Optiflop</li>
</ul>
<p>Note: Optiflop DAXPY results agree with cuBLAS.</p>
</aside>
</section>

<section id="compute-bound" class="title-slide slide level1">
<h1>Compute Bound</h1>
<p>Matrix Multiplication (<code>DGEMM</code>)</p>
<p><span class="math display">\[\text{C}_{ij} = \sum_{k} A_{ik} B_{kj}\]</span><span class="math display">\[\frac{\text{FLOPs}}{\text{byte}}
   = \frac{3n^3}{2n^2 \times \texttt{sizeof}(A)}
   = \frac{3}{16} n\]</span></p>
<p>Efficiency (as work/byte) increases as problem grows</p>
</section>

<section id="memory-bound" class="title-slide slide level1">
<h1>Memory Bound</h1>
<p>Field update (<code>DAXPY</code>)</p>
<p><span class="math display">\[\phi_{ijk} = \phi_{ijk} + \Delta t \mathcal{F}_{ijk}\]</span><span class="math display">\[\frac{\text{FLOPs}}{\text{byte}}
   = \frac{2n}{3n \times \texttt{sizeof} (\phi)}
   = \frac{1}{12}\]</span></p>
<p>Work grows in proportion to bandwidth cost</p>
</section>

<section>
<section id="what-is-our-ai" class="title-slide slide level1">
<h1>What is our AI?</h1>
<p>Traditional incompressible CFD</p>
<p><span class="math display">\[\begin{aligned}
\mathbf{u}^{*} =
   \mathbf{u}^n + \Delta t \left(-\mathbf{u}^n \cdot \nabla \mathbf{u}^n +
   \ldots \right) \\
\end{aligned}\]</span><span class="math display">\[\begin{aligned}
\nabla^2 p^{n+1} = -\nabla \cdot \mathbf{u}^* \\
\end{aligned}\]</span><span class="math display">\[\begin{aligned}
\mathbf{u}^{n+1} = \mathbf{u}^{*} - \nabla^2 p^{n+1} \\
\end{aligned}\]</span></p>
<p>Pressure solver is (sparse) matrix over 3D field</p>
</section>
<section id="atmospheric-solver" class="slide level2">
<h2>Atmospheric Solver</h2>
</section></section>
<section>
<section id="flop-performance" class="title-slide slide level1">
<h1>FLOP performance</h1>
<p><img data-src="img/cascade_lake_flops.svg" alt="image" /></p>
<aside class="notes">
<p>Difference expressions will exhibit</p>
</aside>
</section>
<section id="how-these-are-produced" class="slide level2">
<h2>How these are produced</h2>
<pre class="c"><code>int main() {
   start(timer);
   for (r = 0; r &lt; r_max; r++) {
       for (int i = 0; i &lt; n; i++)
           kernel(i, a, b, x, y);

       // An impossible branch to block loop interchange
       if (y[0] &lt; 0.) dummy(a, b, x, y);
   }
   stop(timer);
}

void kernel(int i, double a, double b, double *x, double *y) {
    y[i] = a * x[i] + y[i];
}</code></pre>
<p>Apply artificially high iteration, but let the compiler construct the kernel.</p>
</section>
<section id="unaccounted-factors" class="slide level2">
<h2>Unaccounted Factors</h2>
<ul>
<li>Pipelining</li>
<li>Instruction latency</li>
<li>Instruction decoder</li>
<li>Variable Clock Frequency</li>
<li>Depletion of registers</li>
</ul>
</section></section>
<section>
<section id="performance-model" class="title-slide slide level1">
<h1>Performance Model</h1>
<p><img data-src="img/cascade_lake_roofline.svg" style="width:60.0%" alt="image" /></p>
<aside class="notes">
<p>Adjacent lines have the same AI</p>
</aside>
</section>
<section id="write-allocate" class="slide level2">
<h2>Write-Allocate</h2>
<p>NOTE: Although most x86 have two Load ports and one store port, they can usually only decode two addresses per cycle! So the net bandwidth is almost always 1L+1S, or 2L with no store.</p>
<p><em>TODO: Make this into a readable slide</em></p>
</section></section>
<section id="roofline-modeling" class="title-slide slide level1">
<h1>Roofline Modeling</h1>
<p><span class="math display">\[P = \text{min}(P_\text{max}, I \times B_\text{mem})\]</span></p>
<ul>
<li><span class="math inline">\(P\)</span>: Performance (FLOP/s)</li>
<li><span class="math inline">\(P_\text{max}\)</span>: Theoretical peak (FLOP/s)</li>
<li><span class="math inline">\(I\)</span>: Arithmetic Intensity (FLOP/byte)</li>
<li><span class="math inline">\(B_\text{mem}\)</span>: Memory bandwidth (byte/s) (cache, RAM, ...)</li>
</ul>
<p>For our codes, <span class="math inline">\(P = I \times B_\text{mem}\)</span></p>
<aside class="notes">
<p>Roofline is a useful model for estimating how well we ought to do</p>
<p>However, it can be hard to apply in practice due to a few issues</p>
<ul>
<li>The "peak" and "memory bandwidth" are deliberately ambiguous and can be hard to assign. (RAM? L3&lt;-&gt;L2? etc?)</li>
<li>No real effort to manage competing timescales in the CPU</li>
</ul>
<p>ECM is an alternative model</p>
<p>We want to keep things very simple and just emphasize the role of bandwidth.</p>
</aside>
</section>

<section>
<section id="modeling-our-results" class="title-slide slide level1">
<h1>Modeling our results</h1>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>Speed (GHz)</th>
<th>Width (B)</th>
<th>Bandwidth (GB/s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 cache</td>
<td>2.8*</td>
<td>128*</td>
<td>8600</td>
</tr>
<tr class="even">
<td>x86 RAM</td>
<td>2.933</td>
<td>8 × 6</td>
<td>141</td>
</tr>
<tr class="odd">
<td>Volta RAM</td>
<td>877</td>
<td>1024</td>
<td>900</td>
</tr>
</tbody>
</table>
<ul>
<li>AVX512 clock speed, L1 load+store, etc</li>
</ul>
</section>
<section id="x86-cache-bandwidth" class="slide level2">
<h2>x86 Cache Bandwidth</h2>
<p><img data-src="img/skylake_reduced_block_diagram.svg" alt="image" /></p>
<p>Cascade Lake has three 64B ports, but in practice can only use two per cycle.</p>
<div class="note">
<div class="title">
<p>Note</p>
</div>
<p><a href="https://blogs.fau.de/hager/archives/8683">https://blogs.fau.de/hager/archives/8683</a></p>
</div>
</section></section>
<section id="euler-step" class="title-slide slide level1">
<h1>Euler Step</h1>
<p><span class="math display">\[\phi^{n+1}_i = \phi^n_i
   + \Delta t \left( \frac{\partial \phi}{\partial t} \right)_i\]</span></p>
<pre class="c"><code>y[i] = y[i] + a * x[i]</code></pre>
<p>2 FLOPs per 24 bytes: <span class="math inline">\(\frac{1}{12}\)</span>*</p>
</section>

<section id="peak-daxpy" class="title-slide slide level1">
<h1>Peak DAXPY</h1>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>Theory</th>
<th>Observed</th>
<th>%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 (Cache)</td>
<td>716.8</td>
<td>715.1</td>
<td>99.7</td>
</tr>
<tr class="even">
<td>x86 (RAM)</td>
<td>11.8</td>
<td>9.36</td>
<td>79.3</td>
</tr>
<tr class="odd">
<td>GPU</td>
<td>74.8</td>
<td>70.9</td>
<td>94.8</td>
</tr>
</tbody>
</table>
<aside class="notes">
<dl>
<dt>x86 reg: (128 B/c * 2.8 GHz) * 24 cores * (1/8 FLOP/B)?</dt>
<dd><p>(128 B/c * 2.8 GHz) * 24 cores * (1/12 FLOP/B)?</p>
</dd>
<dt>x86 mem: (2.933GHz * 8 B/c) * (6 channels) * (1/12 FLOP/byte)</dt>
<dd><p>= 11.732</p>
</dd>
<dt>(NOTE: Bandwidth suggests 1/8 due to 128B/s buses, but the "AGU-limit"</dt>
<dd><p>means only 2 of 3 (2L+S) can be used at a time)</p>
<p><a href="https://blogs.fau.de/hager/archives/8683">https://blogs.fau.de/hager/archives/8683</a></p>
</dd>
</dl>
<p>I can't get this 70.9 number anymore..? Now getting 67.3 or so.</p>
</aside>
</section>

<section>
<section id="finite-difference" class="title-slide slide level1">
<h1>Finite Difference</h1>
<p><span class="math display">\[\phi^{n+1}_i = \phi^n_i + \frac{\Delta t}{\Delta x^2}
   \left(\phi^n_{i+1} - 2 \phi^n_i + \phi^n_{i-1} \right)\]</span></p>
<pre class="c"><code>y[i] = a * x[i] + b * (x[i+1] +  x[i-1])

x[i] = y[i]</code></pre>
<p>4 FLOPs (amortized) per 4 I/O moves: frac{1}{8}</p>
</section>
<section id="results" class="slide level2">
<h2>Results</h2>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>+1</th>
<th>+8</th>
<th>Theory</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x86 (Cache)</td>
<td>732.7</td>
<td>1071.0</td>
<td>1075.2</td>
</tr>
<tr class="even">
<td>x86 (RAM)</td>
<td>18.8</td>
<td>18.9</td>
<td>35.2</td>
</tr>
<tr class="odd">
<td>GPU</td>
<td>162.0</td>
<td>162.1</td>
<td>224.5</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>x86 cache: 64 B/cyc * 2.8G cyc/sec * 0.25 FLOP/byte = 1075.2</p>
<dl>
<dt>x86 RAM: 2.933 GHz * 8B * 6ch = 140.8 GB/s</dt>
<dd><ul>
<li>NOTE: We typically measure ~</li>
</ul>
</dd>
<dt>write-allocate is needed to understand this lower 75 GB/s estimate</dt>
<dd><p>115 = 75 * 1.5</p>
</dd>
</dl>
<p>The 80% efficiency is not really something I can understand...</p>
<p><a href="https://blogs.fau.de/hager/archives/8263">https://blogs.fau.de/hager/archives/8263</a></p>
<p><a href="https://www.cs.virginia.edu/stream/ref.html#counting">https://www.cs.virginia.edu/stream/ref.html#counting</a></p>
</aside>
</section>
<section id="how-many-flops" class="slide level2">
<h2>How many FLOPS?</h2>
<p>Is it four or five operations?</p>
<p><span class="math display">\[\phi^{n+1}_i = \phi^n_i + \frac{\Delta t}{\Delta x^2}
   \left(\phi^n_{i+1} - 2 \phi^n_i + \phi^n_{i-1} \right)\]</span></p>
<pre class=""><code>y[i] = x[i] + a * (x[i-1] - 2 * x[i] + x[i+1])</code></pre>
<p><span class="math display">\[\phi^{n+1}_i = \left( 1 - 2 \frac{\Delta t}{\Delta x^2} \right) \phi^n_i 
   + \frac{\Delta t}{\Delta x^2} \left(\phi^n_{i+1} + \phi^n_{i-1} \right)\]</span></p>
<pre class=""><code>y[i] = a * x[i] + b * (x[i-1] + x[i+1])</code></pre>
<p>This is a compiler question: Do we follow parentheses?</p>
</section></section>
<section id="square-root" class="title-slide slide level1">
<h1>Square Root</h1>
<ul>
<li>without -ffast-math</li>
<li>with -ffast-math</li>
</ul>
</section>

<section id="evaluating-model-performance" class="title-slide slide level1">
<h1>Evaluating Model Performance</h1>
<p><img data-src="img/benchmark_topo.svg" class="float float" style="width:35.0%" alt="image" /></p>
<ul>
<li>192 × 128 grid, 75 level
<ul>
<li>32 x 32 per MPI rank</li>
<li>~1.8M points / field</li>
</ul></li>
<li>288 steps (3 day, <span class="math inline">\(\Delta t = 900s\)</span>)</li>
<li>"Benchmark" configuration:
<ul>
<li>Split barotropic</li>
<li>Smagorinsky biharmonic</li>
<li>Thermo, Wright EOS</li>
<li>Bounded Coriolis terms</li>
<li>Layered (no ALE)</li>
</ul></li>
</ul>
<aside class="notes">
<ul>
<li><p>So how is MOM6 vectorization?</p>
<ul>
<li>This is a compile-time feature, so ought not depend on scaling</li>
</ul></li>
<li><p>Using a "benchmark" single-core test</p>
<ul>
<li>Reasonble set of realistic components</li>
<li>A non-trivial land/sea distribution</li>
</ul></li>
<li><p>Not necessarily the most physically signficant factors. Just the ones which had a significant impact on performance.</p></li>
</ul>
</aside>
</section>

<section id="overview" class="title-slide slide level1">
<h1>Overview</h1>
<p><img data-src="img/mom6_subrt_flops.svg" alt="image" /></p>
</section>

<section id="mom6-roofline" class="title-slide slide level1">
<h1>MOM6 Roofline</h1>
<p><img data-src="img/mom6_roofline.svg" alt="image" /></p>
</section>

<section id="resource-monitoring" class="title-slide slide level1">
<h1>Resource Monitoring</h1>
<table>
<colgroup>
<col style="width: 55%" />
<col style="width: 45%" />
</colgroup>
<tbody>
<tr class="odd">
<td><a href="https://github.com/marshallward/MOM6/runs/2640839721?check_suite_focus=true"><img data-src="img/github_perf.png" alt="image" /></a></td>
<td><ul>
<li>Expose perf metrics to CI</li>
<li>Challenges abound...</li>
</ul></td>
</tr>
</tbody>
</table>
</section>

<section id="hierarchy-of-performance" class="title-slide slide level1">
<h1>Hierarchy of Performance</h1>
<ul>
<li><p>Implement algorithm</p></li>
<li><p>Measure arithmetic intensity (AI)</p></li>
<li><p>Verify vectorization</p>
<ul>
<li>Eliminate unfavorable structures (<strong>do-if-do</strong>)</li>
</ul></li>
<li><p>Reduce array size</p>
<ul>
<li>~1000-2000 iterations seems ideal</li>
</ul></li>
<li><p>Optimize pipeline: 1 Op/cycle</p>
<ul>
<li>Co-locate read/write access</li>
</ul></li>
<li><p>Diagnose performance as % of theoretical peak (wrt hardware &amp; AI)</p></li>
</ul>
</section>

<section id="summary" class="title-slide slide level1">
<h1>Summary</h1>
<ul>
<li>Ocean models in their current form are unlikely to ever perform at peak performance, and will always be bandwidth-limited.</li>
<li>Arithmetic intensity, with machine bandwidths, is a reliable predictor of computational performance</li>
<li>CPUs benefit from modest arrays, can tolerate large arrays</li>
<li>GPUs thrive on large arrays, run poorly on</li>
<li>Best thing we can do is <em>monitor</em> and <em>adjust</em> this situation</li>
<li>Maximize FLOPs <strong>within context of the solver</strong>, but never stop considering better methods</li>
</ul>
</section>
    </div>
  </div>

  <script src="./reveal.js/dist/reveal.js"></script>
  <script src="./reveal.js/plugin/math/math.js"></script>
  <script src="./reveal.js/plugin/notes/notes.js"></script>
  <script src="./reveal.js/plugin/highlight/highlight.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          //TeX: {
          //  inlineMath: [['\\(','\\)']],
          //  displayMath: [['\\[','\\]']],
          //  balanceBraces: true,
          //  processEscapes: false,
          //  processRefs: true,
          //  processEnvironments: true,
          //  preview: 'TeX',
          //  skipTags: ['script','noscript','style','textarea','pre','code'],
          //  ignoreClass: 'tex2jax_ignore',
          //  processClass: 'tex2jax_process'
          //},
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: './reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: './reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: './reveal.js/plugin/notes/notes.js', async: true }
        ],
        plugins : [ RevealMath, RevealNotes, RevealHighlight],
      });
    </script>
    </body>
</html>
